{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from setup import *\n",
    "from ipywidgets import *\n",
    "import file_open\n",
    "import math\n",
    "print(matplotlib.get_backend())\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "# Image upload\n",
    "This notebook processes photos of mayfly eggs and uses blob detection to count the number of eggs in the image. Run the cell below and select a single file to process. The image is converted to greyscale automatically upon uploading. The axes show the image size in pixels to help us select the appropriate size thresholds when setting upi the blob detection algorithm.\n",
    "\n",
    "fileName = file_open.gui_fname()\n",
    "im = cv2.imread(fileName.decode(\"utf-8\"), cv2.IMREAD_GRAYSCALE)\n",
    "h, w = im.shape\n",
    "aspect_ratio = h/w + 0.1\n",
    "width = 9.8\n",
    "fig = plt.figure(figsize=(width,width*aspect_ratio))\n",
    "plt.subplot(111)\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.title('Greayscale original')\n",
    "# plt.axis('off')\n",
    "plt.show()\n",
    "original = im\n",
    "\n",
    "# Image thresholding\n",
    "Firstly, we try to remove all unncesary image artifacts by thresholding the values of each pixel along the greyscale. We will try two types of thresholding: global and adaptive one. In global thresholding, the same threshold value is applied to every pixel in the image. If the pixel value is smaller than the threshold, it is set to 0, otherwise it is set to a maximum value that we define. In the adaptive thresholding, the threshold for each pixel is determined by the small region around it. The first type of thresholding is suitable for images where the lighting is uniform and there are no overexposed areas. The adaptive type is useful for images where the brightness is not uniform. \n",
    "\n",
    "thresholdGlobal = 127\n",
    "pixelNeigbourhood = 11\n",
    "constant = 4\n",
    "del thresh_global\n",
    "ret, thresh_global = cv2.threshold(original,thresh=thresholdGlobal,maxval=255,type=cv2.THRESH_BINARY)\n",
    "thresh_adapt = cv2.adaptiveThreshold(original, maxValue=255, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv2.THRESH_BINARY, blockSize=pixelNeigbourhood, C=constant)\n",
    "# apply morphology open then close to both thresholded images\n",
    "openSize = 5\n",
    "closeSize = 9\n",
    "kernelOpen = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (openSize,openSize))\n",
    "kernelClose = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (closeSize,closeSize))\n",
    "openBlob = cv2.morphologyEx(thresh_adapt, cv2.MORPH_OPEN, kernelOpen)\n",
    "blob_global = cv2.morphologyEx(openBlob, cv2.MORPH_CLOSE, kernelClose)\n",
    "openBlob = cv2.morphologyEx(thresh_adapt, cv2.MORPH_OPEN, kernelOpen)\n",
    "blob_adapt = cv2.morphologyEx(openBlob, cv2.MORPH_CLOSE, kernel)\n",
    "# plot\n",
    "numCols, numRows = 2, 2\n",
    "fig, axes = plt.subplots(numRows,numCols, figsize=((width,width*aspect_ratio*numRows/numCols)))\n",
    "plotter_thresh_g = axes[0,0].imshow(thresh_global, cmap='gray')\n",
    "axes[0,0].set_title('Global thresholding')\n",
    "axes[0,0].axis('off')\n",
    "plotter_blob_g = axes[0,1].imshow(blob_global, cmap='gray')\n",
    "axes[0,1].set_title('Associated blobs')\n",
    "axes[0,1].axis('off')\n",
    "plotter_thresh_a = axes[1,0].imshow(thresh_adapt, cmap='gray')\n",
    "axes[1,0].set_title('Adaptive thresholding')\n",
    "axes[1,0].axis('off')\n",
    "plotter_blob_a = axes[1,1].imshow(blob_adapt, cmap='gray')\n",
    "axes[1,1].set_title('Associated blobs')\n",
    "axes[1,1].axis('off')\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()\n",
    "# interactive part\n",
    "def update_morphology(threshold_upd,block_upd,const_upd,openSize_upd,closeSize_upd):\n",
    "    ret,thresh_global = cv2.threshold(original,thresh=threshold_upd,maxval=255,type=cv2.THRESH_BINARY)\n",
    "    thresh_adapt = cv2.adaptiveThreshold(original, maxValue=255, adaptiveMethod=cv2.ADAPTIVE_THRESH_MEAN_C, thresholdType=cv2.THRESH_BINARY, blockSize=block_upd, C=const_upd)\n",
    "    kernelOpen = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (openSize_upd,openSize_upd))\n",
    "    kernelClose = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (closeSize_upd,closeSize_upd))\n",
    "    openBlob = cv2.morphologyEx(thresh_global, cv2.MORPH_OPEN, kernelOpen)\n",
    "    blob_global = cv2.morphologyEx(openBlob, cv2.MORPH_CLOSE, kernelClose)\n",
    "    openBlob = cv2.morphologyEx(thresh_adapt, cv2.MORPH_OPEN, kernelOpen)\n",
    "    blob_adapt = cv2.morphologyEx(openBlob, cv2.MORPH_CLOSE, kernelClose)\n",
    "    plotter_thresh_g.set_data(thresh_global)\n",
    "    plotter_blob_g.set_data(blob_global)\n",
    "    plotter_thresh_a.set_data(thresh_adapt)\n",
    "    plotter_blob_a.set_data(blob_adapt)\n",
    "    fig.canvas.draw_idle()\n",
    "# sliders\n",
    "thr_slider0 =  widgets.IntSlider(min=1, max=254, step=1, value=thresholdGlobal, description='Global threshold',style=style) \n",
    "thr_slider1 =  widgets.IntSlider(min=3, max=200, step=1, value=pixelNeigbourhood, description='Neighbourhood area',style=style) \n",
    "thr_slider2 = widgets.IntSlider(min=1, max=100, step=1, value=constant, description='Constant',style=style)\n",
    "w_slider1 =  widgets.IntSlider(min=3, max=55, step=2, value=open_size, description='Open kernel size',style=style) \n",
    "w_slider2 = widgets.IntSlider(min=3, max=55, step=2, value=close_size, description='Close kernel size',style=style)\n",
    "interact(update_morphology,threshold_upd=thr_slider0, block_upd=thr_slider1,const_upd=thr_slider2,openSize_upd=w_slider1,closeSize_upd=w_slider2);\n",
    "\n",
    "# Denoising the image\n",
    "Prior to running the detection algorithm, the image can be denoised to prevent falsely detecting image noise as eggs.\n",
    "The smoothing procedure \"blurres\" the photo - we may benifinte from it as it slightly erodes the border of your eggs. Choose one of the methods below:\n",
    "\n",
    "im = blob_adapt\n",
    "fig = plt.figure(figsize=(width,width*aspect_ratio/2))\n",
    "plt.ion()\n",
    "ax_mean = plt.subplot(121)\n",
    "ax_med = plt.subplot(122)\n",
    "im_mean = cv2.blur(im, (5, 5))\n",
    "im_med = cv2.medianBlur(im, 5)\n",
    "plotter_mean = ax_mean.imshow(im_mean, cmap='gray')\n",
    "plotter_med = ax_med.imshow(im_med, cmap='gray')\n",
    "ax_med.set_title('Median smoother')\n",
    "ax_mean.set_title('Mean smoother')\n",
    "ax_med.axis('off')\n",
    "ax_mean.axis('off')\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()\n",
    "def update_mean(MeanFilterSize):\n",
    "    im_mean = cv2.blur(im, (MeanFilterSize, MeanFilterSize))\n",
    "    plotter_mean.set_data(im_mean)\n",
    "    fig.canvas.draw_idle()\n",
    "def update_median(MedianFilterSize):\n",
    "    im_med = cv2.medianBlur(im, MedianFilterSize)\n",
    "    plotter_med.set_data(im_med)\n",
    "    fig.canvas.draw_idle()\n",
    "interact(update_mean, MeanFilterSize=widgets.IntSlider(min=1,max=55,step=2,value=5, description='Mean filter size',style=style));\n",
    "interact(update_median, MedianFilterSize=widgets.IntSlider(min=1,max=55,step=2,value=5, description='Median filter size',style=style));\n",
    "\n",
    "There are more sophisticated smoothers that can be used for denoising, but generally we should be able to get away without them. We can use examples the Bergman smoother and the fast means smoother. If they produce a smoother image, you can select them for further processing.\n",
    "\n",
    "fig = plt.figure(figsize=(width,width*aspect_ratio/2))\n",
    "plt.ion()\n",
    "ax_berg = plt.subplot(121)\n",
    "ax_cons = plt.subplot(122)\n",
    "im_bergman = img_as_ubyte(denoise_tv_bregman(im, weight=1.2, channel_axis=None))\n",
    "im_fm_blur = cv2.fastNlMeansDenoising(im, None, 20, 15, 35)\n",
    "plotter_berg = ax_berg.imshow(im_bergman, cmap='gray')\n",
    "plotter_cons = ax_cons.imshow(im_fm_blur, cmap='gray')\n",
    "ax_berg.set_title('Bergman smoother')\n",
    "ax_cons.set_title('Fast Means smoother')\n",
    "ax_berg.axis('off')\n",
    "ax_cons.axis('off')\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()\n",
    "def update_berg(BergmanFilterSize):\n",
    "    im_bergman = img_as_ubyte(denoise_tv_bregman(im, weight=BergmanFilterSize, channel_axis=None))\n",
    "    plotter_berg.set_data(im_bergman)\n",
    "    fig.canvas.draw_idle()\n",
    "def update_fastMeans(ConservativeFilterSize,TempWindSize,SearchWindSize):\n",
    "    im_fm_blur = cv2.fastNlMeansDenoising(im,  None, ConservativeFilterSize, TempWindSize, SearchWindSize)\n",
    "    plotter_cons.set_data(im_fm_blur)\n",
    "    fig.canvas.draw_idle()\n",
    "interact(update_berg, BergmanFilterSize=widgets.FloatSlider(min=0.5, max=5., step=0.1, value=1.2,  description='Bergman filter weight',style=style));\n",
    "w_slider1 =  widgets.IntSlider(min=5, max=25, step=2, value=15, description='Template window size',style=style) \n",
    "w_slider2 = widgets.IntSlider(min=17, max=55, step=2, value=35, description='Search window size',style=style)\n",
    "h_slider = widgets.FloatSlider(min=5.0, max=50.0, step=0.1, value=20.0, description='Fast means filter weight',style=style)\n",
    "interact(update_fastMeans, ConservativeFilterSize=h_slider,TempWindSize=w_slider1,SearchWindSize=w_slider2);\n",
    "\n",
    "\n",
    "\n",
    "After the smoothing is done, select which outputs you wish to process further in the cell below.\n",
    "\n",
    "list_of_images = [im, im_mean, im_med, im_bergman, im_fm_blur]\n",
    "list_of_titles = ['Original','Mean smoothed', 'Median smoothed', 'Bergman smoothed','Fast Means smoothed']\n",
    "checkboxes = [widgets.Checkbox(value=False, description=label) for label in list_of_titles]\n",
    "output = widgets.VBox(children=checkboxes)\n",
    "display(output)\n",
    "\n",
    "## Run the cell below whenever you select or de-select a checkbox in the list above!\n",
    "\n",
    "    selected_images = []\n",
    "    selected_titles = []\n",
    "    for i in range(0, len(checkboxes)):\n",
    "        if checkboxes[i].value == True:\n",
    "            selected_titles = selected_titles + [checkboxes[i].description]\n",
    "            selected_images.append(list_of_images[i])\n",
    "    print(selected_titles)\n",
    "\n",
    "# Image erosion\n",
    "If there are many overlapping eggs in the photo, or they are located closely togerher so that the boundaries are indistinguishable, we can erode the image by convolving it with a kernel - a square matrix of odd size (can take values above 3). In the erosion process, a pixel of the image is set to 1 if all pixels in the kernel surrounding it are also 1. Otherwise, it is set to 0. The erosion process may reduce the area of the eggs on the image, but will create more pronounced boundaries between them The slider below sets the size of the kernel matrix. \n",
    "\n",
    "# initial kernel size\n",
    "initSize = 5\n",
    "# create kernel\n",
    "kernel = np.ones((initSize, initSize), np.uint8)\n",
    "# erode images from the list of images selected above\n",
    "numCols = 2\n",
    "numRows = math.ceil(len(list_of_images)/numCols)\n",
    "fig, axes =  plt.subplots(numRows, numCols, figsize=(width,width*aspect_ratio*numRows/numCols))\n",
    "plt.ion()\n",
    "#  loop over the images that were selected above and stored into the list\n",
    "plotters = []\n",
    "eroded_titles = []\n",
    "eroded_images = []\n",
    "for iImage, image in enumerate(selected_images):\n",
    "    eroded_titles.append('Eroded ' + selected_titles[iImage])\n",
    "    ax = axes.flatten()[iImage]\n",
    "    im_eroded = cv2.erode(255-image, kernel, iterations=1)\n",
    "    eroded_images.append(im_eroded)\n",
    "    plotters.append(ax.imshow(im_eroded, cmap='gray'))\n",
    "    ax.set_title(eroded_titles[iImage])\n",
    "    ax.axis('off')\n",
    "if iImage < numRows*2:\n",
    "    for iEmptyImage in range(iImage+1,numRows*2):\n",
    "        ax = axes.flatten()[iEmptyImage]\n",
    "        fig.delaxes(ax)\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "def update_erode(KernelSize):\n",
    "    #  update the kernel and run the erosion  \n",
    "    kernel = np.ones((KernelSize, KernelSize), np.uint8)\n",
    "    for iImage, image in enumerate(selected_images):\n",
    "        ax = axes.flatten()[iImage]\n",
    "        im_eroded = cv2.erode(255-image, kernel, iterations=1)\n",
    "        eroded_images[iImage] = im_eroded\n",
    "        plotters[iImage].set_data(im_eroded)\n",
    "    fig.canvas.draw_idle()\n",
    "interact(update_erode, KernelSize=widgets.IntSlider(min=3,max=35,step=2,value=initSize, description='Kernel size',style=style));\n",
    "\n",
    "checkboxes1 = [widgets.Checkbox(value=False, description=label) for label in eroded_titles]\n",
    "output = widgets.VBox(children=checkboxes1)\n",
    "display(output)\n",
    "\n",
    "## Run the cell below whenever you select or de-select a checkbox in the list above!\n",
    "\n",
    "    selected_images1 = []\n",
    "    selected_titles1 = []\n",
    "    for i in range(0, len(checkboxes1)):\n",
    "        if checkboxes1[i].value == True:\n",
    "            selected_titles1 = selected_titles1 + [checkboxes1[i].description]\n",
    "            selected_images1.append(eroded_images[i])\n",
    "    print(selected_titles1)\n",
    "\n",
    "numRows = len(selected_titles1)\n",
    "numCols = 2\n",
    "blobbed_images = []\n",
    "fig, axes = plt.subplots(numRows,numCols, figsize=(width,width*aspect_ratio*numRows/numCols))\n",
    "for iRow, image in enumerate(selected_images1):\n",
    "    # check the method from stack exchange on thresholding\n",
    "    thresh = cv2.adaptiveThreshold(im, 225, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 65, 3)\n",
    "    # apply morphology open then close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    blob = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "    blob = cv2.morphologyEx(blob, cv2.MORPH_CLOSE, kernel)\n",
    "    blobbed_images.append(blob)\n",
    "    axes[iRow,0].imshow(im, cmap='gray')\n",
    "    axes[iRow,0].set_title(selected_titles1[iRow])\n",
    "    axes[iRow,0].axis('off')\n",
    "    axes[iRow,1].imshow(blob, cmap='gray')\n",
    "    axes[iRow,1].set_title('Blobs')\n",
    "    axes[iRow,1].axis('off')\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "# Contrast adjustment\n",
    "We can adjust the contrast of the images to make sure there are no over- or underexposed areas in the image. This ensures that the detection algorithm will find blobs everywhere in the image with the same settings.\n",
    "\n",
    "# create clahe object that defines the matrix\n",
    "tileSize = 70\n",
    "clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(tileSize, tileSize))\n",
    "\n",
    "# Blob detection\n",
    "Create a detector with the set of parameters. This is the part where we do most of the parameter tuning. We will be usingseveral features of the \"blobs\" (the eggs) to threshold them from other image artifacts: area size, circularity, convexity, inertia, and color. The image should help to navigate these features. In the image, the values of all features of interes increase from left to right. For example, the colour values closer to 0 represent lighter shades of grey, and values closer to 255 darker shade.\n",
    "![BlobTest.jpg](attachment:BlobTest.jpg)\n",
    "By default the thresholding in this detection algorithm is done by colour. You can select other filters for thresholding in the cell below.\n",
    "\n",
    "# Set up the detector with default parameters:\n",
    "detector = cv2.SimpleBlobDetector()\n",
    "# Setup SimpleBlobDetector parameters\n",
    "list_of_filters = ['Filter by area','Filter by circularity', 'Filter by convexity', 'Filter by inertia']\n",
    "checkboxes2 = [widgets.Checkbox(value=False, description=label) for label in list_of_filters]\n",
    "output = widgets.VBox(children=checkboxes2)\n",
    "display(output)\n",
    "\n",
    "In the cell below you can change the detector parameter values for each filter. \n",
    "## You will have to re-run the cell below every time you change any of the values!\n",
    "\n",
    "# images to process\n",
    "images_to_detect = selected_images1\n",
    "# Turn on filters selected in the checkboxes above\n",
    "filters = []\n",
    "for i in range(0, len(checkboxes2)):\n",
    "    filters = filters + [checkboxes2[i].value]\n",
    "print(filters)\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.filterByArea, params.filterByCircularity, params.filterByConvexity, params.filterByInertia  = filters\n",
    "###################################################################################################################\n",
    "# SET PARAMETERS OF THE DETECTOR HERE\n",
    "# # The most basic way to detect the blobs is by limiting the hue of the greyscale image.\n",
    "# # note that the colors run from 0 = white to 255 = black.\n",
    "params.minThreshold = 10\n",
    "params.maxThreshold = 500\n",
    "\n",
    "# Filter by Area. In this case, there is no clear upper or lower limit - the area is defined in pixels and will depend strongly on your image resolution.\n",
    "params.minArea = 50 # must be >0, but the min area will depend on image resolution\n",
    "params.maxArea = 200 # must be >minArea, but the max area willwill depend on image resolution\n",
    "\n",
    "# # Filter by Circularity: 1 - perfect circle, 0 - any shape\n",
    "params.minCircularity = 0.01\n",
    "params.maxCircularity = 1\n",
    "#\n",
    "# # Filter by Convexity 1 - perfectly convex, 0 - allows for many concave areas\n",
    "params.minConvexity = 0.01 # can take values from 0 to 1\n",
    "params.maxConvexity = 1 # can take values from minCovnexity to 1\n",
    "\n",
    "# # Filter by Inertia - how long is elongated the is ellipse allowed to be\n",
    "params.minInertiaRatio = 0.01 # can take values from 0 to 1\n",
    "params.minInertiaRatio = 1 # can take values from minInertiaRatio to 1\n",
    "# end of changable part\n",
    "###################################################################################################################\n",
    "# The code below creates a detector with the parameters we have set in this cell\n",
    "ver = (cv2.__version__).split('.')\n",
    "if int(ver[0]) < 3:\n",
    "    detector = cv2.SimpleBlobDetector(params)\n",
    "else:\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "    \n",
    "#  run the blob detection for all selected images\n",
    "numCols = 2\n",
    "numRows = math.ceil(len(images_to_detect)/numCols)\n",
    "fig, axes =  plt.subplots(numRows, numCols, figsize=(width,width*aspect_ratio*numRows/numCols))\n",
    "plt.ion()\n",
    "#  loop over the images that were selected above and stored into the list\n",
    "for iImage, image in enumerate(images_to_detect):   \n",
    "    ax = axes.flatten()[iImage]\n",
    "    image = 255-image\n",
    "    keypoints = detector.detect(image)\n",
    "    blank = np.zeros((1, 1)) #    blank = np.zeros((1, 1)) #\n",
    "    im_with_keypoints = cv2.drawKeypoints(image, keypoints, blank, (255, 165, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    ax.imshow(im_with_keypoints)\n",
    "    ax.set_title(list_of_titles[iImage])\n",
    "    ax.set_xlabel('Blob count = '+ str(len(keypoints)))\n",
    "    # Hide X and Y axes label marks\n",
    "    ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.yaxis.set_tick_params(labelleft=False)\n",
    "    # Hide X and Y axes tick marks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "if iImage < numRows*2:\n",
    "    for iEmptyImage in range(iImage+1,numRows*2):\n",
    "        ax = axes.flatten()[iEmptyImage]\n",
    "        fig.delaxes(ax)\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
